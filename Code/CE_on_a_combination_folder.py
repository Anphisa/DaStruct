from json import dumps
from os import listdir
from os.path import isfile, join
import csv
import openpyxl
from CentralExecutive import CentralExecutive

__author__ = 'Phaina'

"""
Import csv files (from PRISM), create premise and conclusion files for my implementation.
Go through a folder with premise files, build parameters.json and start CentralExecutive for a run.
Read instance statistics file (output from CentralExecutive) and put data into a collective csv file for each folder.
"""


class CE_on_a_folder(object):
    def __init__(self, directory, excel_file, lines_from, lines_to):
        """
        Automatically go through a given batch of problem files, construct .pf files out of them that CentralExecutive
        can work on (+ parameters.json with any configuration) and analyze that output.

        :param directory: The directory that problem files and the output of CentralExecutive on them should be saved to
        :param excel_file: The excel file that the problems are in
               (generated by PRISM: http://spatialmentalmodels.appspot.com/data)
        :param lines_from: Where the premises & conclusions start in the excel file
        :param lines_to: Where the premises & conclusions stop in the excel file
        """
        self.correct_percentage = None
        self.answers_prism = None
        self.validities = None
        self.indeterminates = None
        self.consistencies = None
        self.PRISM_difficulties = None
        self.premise_files_from_csv(excel_file, lines_from, lines_to, directory)
        self.CE_on_a_folder(directory)
        self.instance_statistics_to_csv(directory)

    def premise_files_from_csv(self, excel_file, lines_from, lines_to, directory):
        workbook = openpyxl.load_workbook(excel_file)
        sheet = workbook.active
        correct_percentage = {}
        answers_prism = {}
        validities = {}
        indeterminates = {}
        consistencies = {}
        difficulties_PRISM = {}

        for i in range(lines_from, lines_to + 1):
            if i % 2 == 1:
                id_of_game = sheet['C' + str(i)].value
                prem_1 = sheet['D' + str(i)].value
                prem_2 = sheet['E' + str(i)].value
                prem_3 = sheet['F' + str(i)].value
                concl = sheet['G' + str(i)].value
                correct_1 = sheet['R' + str(i)].value
                answer_prism = sheet['B' + str(i + 1)].value
                validity = sheet['C' + str(i + 1)].value
                indeterminate = sheet['D' + str(i + 1)].value
                consistent = sheet['H' + str(i)].value
                PRISM_difficulty = sheet['I' + str(i + 1)].value
                with open(directory + excel_file.split('/')[-1][:-5] + "_" + str(id_of_game) + ".pf", "w") as prem_file:
                    prem_file.write("P: " + prem_1 + "\n")
                    if prem_2:
                        prem_file.write("P: " + prem_2 + "\n")
                    if prem_3:
                        prem_file.write("P: " + prem_3 + "\n")
                    prem_file.write("C: " + concl)
                correct_percentage[int(id_of_game)] = int(correct_1)
                answers_prism[int(id_of_game)] = int(answer_prism)
                validities[int(id_of_game)] = int(validity)
                indeterminates[int(id_of_game)] = int(indeterminate)
                consistencies[int(id_of_game)] = int(consistent)
                difficulties_PRISM[int(id_of_game)] = int(PRISM_difficulty)
        self.correct_percentage = correct_percentage
        self.answers_prism = answers_prism
        self.validities = validities
        self.indeterminates = indeterminates
        self.consistencies = consistencies
        self.PRISM_difficulties = difficulties_PRISM
        print str(((lines_to - lines_from) / 2.) + 1) + " Premise files generated."

    def CE_on_a_folder(self, directory):
        premise_files = [f for f in listdir(directory) if isfile(join(directory, f)) and f.endswith(".pf")]
        # data_structures = ["InfiniteList", "BoundedList"]
        data_structures = ["BinarySearchTree", "BinarySearchTreeLimitedDepth", "BinarySearchTreeRandomTree", "BinarySearchTreeTrivial"]
        # data_structures = ["Graph"]
        # data_structures = ["LinkedList"]
        insert_types = ["ff"]
        merge_types = ["supermodel"]
        # See https://en.wikipedia.org/wiki/Activation_function#Comparison_of_activation_functions
        activation_functions = ['x - 10', 'sum([exp(1)**(-((x - n)/2.)) for n in timesteps])',
                                'sum([exp(1)**(-((x - n)/3.)) for n in timesteps])',
                                '(lambda x: 2 if x > 2 else 3)(x)']

        for file in premise_files:
            for data_structure in data_structures:
                for insert_type in insert_types:
                    for merge_type in merge_types:
                        if data_structure == "BoundedList":
                            bounded_list_size_limit = [i for i in range(2, 4)]
                        else:
                            bounded_list_size_limit = [10]
                        if data_structure == "BinarySearchTreeLimitedDepth":
                            BST_depth_limit = [i for i in range(2, 4)]
                        else:
                            BST_depth_limit = [10]
                        if merge_type == "supermodel":
                            nested_supermodels = [i for i in range(2)]
                        else:
                            nested_supermodels = [10]
                        for how_far_removed in range(1):
                            for limit in bounded_list_size_limit:
                                for bst_limit in BST_depth_limit:
                                    for nested in nested_supermodels:
                                        for activation_function in activation_functions:
                                            data = {
                                                "filename": directory + str(file),
                                                "data_structure": data_structure,
                                                "insert_type": insert_type,
                                                "merge_type": merge_type,
                                                "nested_supermodels": nested,
                                                "neighborhood_graph_removal_cap": how_far_removed,
                                                "bounded_list_size_limit": limit,
                                                "BST_depth_limit": bst_limit,
                                                "verbose": 0,
                                                "to_file": 1,
                                                "activation_function": activation_function
                                            }
                                            with open("parameters.json", "w") as parameters:
                                                parameters.write(dumps(data))
                                            print "Now executing", file, data_structure, insert_type, merge_type, \
                                                how_far_removed, bst_limit, nested, activation_function
                                            CE = CentralExecutive("parameters.json")
                                            CE.execute()
        print "Finished executing problem files."

    def instance_statistics_to_csv(self, directory):
        instance_statistics = [f for f in listdir(directory) if isfile(join(directory, f)) and f.endswith(".txt")]
        ofile = open(directory + "evaluation.csv", "wb")
        writer = csv.writer(ofile, delimiter='	', quotechar='"', quoting=csv.QUOTE_ALL)

        writer.writerow([str(directory)])
        writer.writerow("" "")
        writer.writerow(['ID', 'Data structure', 'Insert type', 'Merge type', 'Nested supermodels',
                         'Neighborhood graph removal cap',
                         'Bounded list size limit', 'BST depth limit', 'Activation function', 'Conclusion',
                         'Move operations for focus',
                         'Move distance for focus', 'Write operations', 'Insert operations', 'Merge operations',
                         'Supermodels created', 'Supermodels accessed', 'Premise direction changes',
                         'Focus direction changes',
                         'Model in attention/focus changes', 'Annotation operations', 'Grouping operations',
                         'Size of grouped models', 'BST depth', 'Focus key distance in BST',
                         'Followed pointer in linked list', 'Amount of relationships in graph',
                         'Single models/layers created',
                         'Single models/layers deleted', 'Sum of all difficulty measures', 'Sum of focus ops',
                         'Sum of focus ops (no distance)', 'Sum of focus ops (only distance)', 'Sum of merge ops',
                         'Sum of model ops', 'correct1', 'valid', 'answer PRISM', 'difficulty PRISM',
                         'indeterminate', 'consistent'])

        line_number = 1
        for instance in instance_statistics:
            with open(directory + instance, "r") as f:
                lines = f.readlines()
            move_ops = 0
            move_distance = 0
            write_ops = 0
            insert_ops = 0
            merge_ops = 0
            supermodels_created = 0
            supermodels_accessed = 0
            premise_direction_changes = 0
            focus_direction_changes = 0
            model_in_attention_changes = 0
            annotation_ops = 0
            grouping_ops = 0
            grouping_size = 0
            BST_depth = 0
            focus_key_distance = 0
            linked_list_followed_pointer = 0
            graph_amount_relationships = 0
            layers_created = 0
            layers_deleted = 0
            for line in lines:
                id = instance.split("_")[1]
                if line.startswith("Data_structure"):
                    data_structure = line.split()[1]
                if line.startswith("Insert_type"):
                    insert_type = line.split()[1]
                if line.startswith("Merge_type"):
                    merge_type = line.split()[1]
                if line.startswith("Nested_supermodels"):
                    nested_supermodels = line.split()[1]
                if line.startswith("Neighborhood_graph_removal_cap"):
                    neighborhood_graph_removal_cap = line.split()[1]
                if line.startswith("Bounded_list_size_limit"):
                    bounded_list_size_limit = line.split()[1]
                if line.startswith("BST_depth_limit"):
                    BST_depth_limit = line.split()[1]
                if line.startswith("Activation function"):
                    activation_function = line[21:]
                if line.startswith("Conclusion "):
                    conclusion = line.split()[-1][:-1]
                if line.count("move operations for focus, "):
                    move_ops = line.split()[0]
                if line.count("move distance for focus, "):
                    move_distance = line.split()[0]
                if line.count("write operations, "):
                    write_ops = line.split()[0]
                if line.count("insert operations, "):
                    insert_ops = line.split()[0]
                if line.count("merge operations, "):
                    merge_ops = line.split()[0]
                if line.count("supermodels created, "):
                    supermodels_created = line.split()[0]
                if line.count("supermodels accessed, "):
                    supermodels_accessed = line.split()[0]
                if line.count("premise direction changes, "):
                    premise_direction_changes = line.split()[0]
                if line.count("focus direction changes, "):
                    focus_direction_changes = line.split()[0]
                if line.count("model in attention/focus changes, "):
                    model_in_attention_changes = line.split()[0]
                if line.count("annotation operations made, "):
                    annotation_ops = line.split()[0]
                if line.count("grouping operations, "):
                    grouping_ops = line.split()[0]
                if line.count("was the size of all grouped models which were merged, "):
                    grouping_size = line.split()[0]
                if line.count("was the BST depth, "):
                    BST_depth = line.split()[0]
                if line.count("was the focus key distance in a BST, "):
                    focus_key_distance = line.split()[0]
                if line.count("was the number of times a pointer in a linked list was followed, "):
                    linked_list_followed_pointer = line.split()[0]
                if line.count("was the amount of relationships recorded in a graph, "):
                    graph_amount_relationships = line.split()[0]
                if line.count("single models (=layers) created, "):
                    layers_created = line.split()[0]
                if line.count("delete layer operations. "):
                    layers_deleted = line.split()[0]
                sum_of_difficulties = int(move_ops) + int(move_distance) + int(write_ops) + int(insert_ops) \
                                      + int(merge_ops) + int(supermodels_created) + int(supermodels_accessed) \
                                      + int(premise_direction_changes) + int(focus_direction_changes) \
                                      + int(model_in_attention_changes) + int(annotation_ops) + int(grouping_ops) \
                                      + int(grouping_size) + int(BST_depth) + float(focus_key_distance) \
                                      + int(layers_created) + int(layers_deleted) + int(linked_list_followed_pointer) \
                                      + int(graph_amount_relationships)
                sum_of_focus_ops = int(move_ops) + int(move_distance) + int(focus_direction_changes) \
                                   + int(model_in_attention_changes)
                sum_of_focus_ops_no_distance = sum_of_focus_ops - int(move_distance)
                sum_of_focus_ops_only_distance = sum_of_focus_ops - int(move_ops)
                sum_of_merge_ops = int(merge_ops) + int(supermodels_created) + int(supermodels_accessed) \
                                   + int(grouping_ops) + int(grouping_size)
                sum_of_model_ops = int(supermodels_created) + int(model_in_attention_changes) + int(layers_created) \
                                   + int(layers_deleted)
                correct_1 = self.correct_percentage[int(id)]
                valid = self.validities[int(id)]
                answer_prism = self.answers_prism[int(id)]
                indeterminate = self.indeterminates[int(id)]
                consistent = self.consistencies[int(id)]
                difficulty_PRISM = self.PRISM_difficulties[int(id)]
            line_number += 1
            print "At line ", line_number
            writer.writerow([id, data_structure, insert_type, merge_type, nested_supermodels,
                             neighborhood_graph_removal_cap,
                             bounded_list_size_limit, BST_depth_limit, activation_function, conclusion, move_ops,
                             move_distance, write_ops,
                             insert_ops, merge_ops, supermodels_created, supermodels_accessed, premise_direction_changes,
                             focus_direction_changes, model_in_attention_changes, annotation_ops, grouping_ops,
                             grouping_size, BST_depth, focus_key_distance, linked_list_followed_pointer, graph_amount_relationships,
                             layers_created, layers_deleted,
                             sum_of_difficulties, sum_of_focus_ops, sum_of_focus_ops_no_distance,
                             sum_of_focus_ops_only_distance, sum_of_merge_ops, sum_of_model_ops, correct_1,
                             valid, answer_prism, difficulty_PRISM, indeterminate, consistent])


if __name__ == '__main__':
    CE_on_a_folder("./experimental_data/Combined_data/comparison1_activation_function/",
                   "./experimental_data/Combined_data/comparison1.xlsx", 3, 129)
